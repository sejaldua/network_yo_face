{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally adapted from [this blog post](https://vedransekara.github.io/) by Vedran Sekara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    \"\"\"Transform color to grayscale.\"\"\"\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**\n",
    "\n",
    "The file has to be in either PNG or JPEG format. For the best results, make sure the background is completely transparent (PNG only). You can do this at [lunapic](https://www298.lunapic.com/editor/?action=transparent) or in Apple Keynote using the *Instant Alpha* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"akon\"\n",
    "nsamples = 10000   # Number of nodes\n",
    "k_max = 10         # The maximum number of links per node\n",
    "k_min = 3          # The maximum number of links per node\n",
    "contrast = 2       # Increase to when skin is darker (2-3 is good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample from image**\n",
    "\n",
    "Depending on skin-color, the clear skin areas will typically be brigter and have higher intensity than the features of the face. This is inverted, to highlight features with lots of nodes and links and not clear areas (like forehead and cheeks). Subsequently we sample points from the data, and bias the sampling by the inteisities raised to the `power` parameter defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "img = plt.imread('%s.png' % filename)\n",
    "data = rgb2gray(img)\n",
    "data = (1 - data / data.max()) * (img[:, :, 3] != 0)  # Invert and zero out background\n",
    "y_norm, x_norm = map(float, data.shape)\n",
    "r = x_norm / y_norm\n",
    "\n",
    "# Sample\n",
    "p_map = data**contrast / np.sum(data**contrast)              # Probability of each pixel\n",
    "ij = np.random.choice(\n",
    "    np.arange(0, data.shape[0] * data.shape[1]),       # Flattened indices\n",
    "    size=nsamples, p=p_map.reshape(-1)\n",
    ")\n",
    "\n",
    "# Sampled coordinates\n",
    "X = np.array(zip(\n",
    "    ij / data.shape[1],                          # x coordinates\n",
    "    ij % data.shape[1]                           # y coordinates\n",
    ")) + (np.random.random(size=(nsamples, 2))-0.5)  # small jitter to rid the gridder\n",
    "\n",
    "# Nearest neighbors\n",
    "tree = cKDTree(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define all the links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for position of links\n",
    "x, y = [], []\n",
    "\n",
    "# Go through each node and construct links \n",
    "for pt in X:\n",
    "    k = int(data[int(round(pt[0])), int(round(pt[1]))] / np.max(data) * (k_max - k_min) + k_min)\n",
    "    dist, ind = tree.query(ptgit, k=k)\n",
    "    for kneigh in ind[1:]:\n",
    "        x.append([pt[0],X[kneigh][0]])\n",
    "        y.append([pt[1],X[kneigh][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we draw and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct figure\n",
    "plt.figure(figsize=(5*r, 5))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.plot(np.array(x).T, np.array(y).T, color='#282828', lw=0.4, alpha=0.4, zorder=2) \n",
    "\n",
    "plt.axis('off')\n",
    "plt.ylim(y_norm, 0)\n",
    "plt.xlim(0, x_norm)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('%s_bot%d_pow%.01fsampling_kmin%d_kmax%d.png' % (filename, nsamples, contrast, k_min, k_max), dpi=250, pad=0.0, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
