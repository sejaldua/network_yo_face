{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert an image of a face to a network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted from [this blog post](https://vedransekara.github.io/) by Vedran Sekara.\n",
    "\n",
    "**The original code** takes a solid black and white image and *converts it to a network*, by sampling points randomly inside the black region and connects the points to their nearest neighbors.\n",
    "\n",
    "**This code** does almost the same, except the sampling is biased by the greyscale pixel intensity, and the number of links for each sampled point scales with the darkness of the region in which it was sampled. It works well for faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/ulfaslak/anaconda2/lib/python2.7/site-packages\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    \"\"\"Transform color to grayscale.\"\"\"\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**\n",
    "\n",
    "The input file has to be in either PNG or JPEG format. For the best results, use PNG and make sure the background is completely transparent. You can, for example, do this with [lunapic](https://www298.lunapic.com/editor/?action=transparent) or in Apple Keynote using the *Instant Alpha* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"ulf\"\n",
    "nsamples = 10000   # Number of nodes\n",
    "k_max = 10         # The maximum number of links per node\n",
    "k_min = 3          # The maximum number of links per node\n",
    "contrast = 2       # Increase to when skin is darker (2-3 is good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample from image**\n",
    "\n",
    "Depending on skin-color, the clear skin areas will typically be brigter and have higher intensity than the features of the face. For faces though, we want dark regions to have lots of links in the network. Therefore, we invert the image, to highlight darker regions with lots of nodes and links. Subsequently we sample points from the data, and bias the sampling by the intensities exponentiated by `contrast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "img = plt.imread('%s.png' % filename)\n",
    "data = rgb2gray(img)\n",
    "data = (1 - data / data.max()) * (img[:, :, 3] != 0)  # Invert and zero out background\n",
    "data = data.T                                         # Transpose coordinate rotation\n",
    "x_norm, y_norm = map(float, data.shape)\n",
    "r = x_norm / y_norm\n",
    "\n",
    "# Sample\n",
    "p_map = data**contrast / np.sum(data**contrast)        # Probability of each pixel\n",
    "ij = np.random.choice(\n",
    "    np.arange(0, data.shape[0] * data.shape[1]),       # Flattened indices\n",
    "    size=nsamples, p=p_map.reshape(-1)\n",
    ")\n",
    "\n",
    "# Sampled coordinates\n",
    "X = np.array(zip(\n",
    "    ij / data.shape[1],                          # x coordinates\n",
    "    ij % data.shape[1]                           # y coordinates\n",
    ")) + (np.random.random(size=(nsamples, 2))-0.5)  # small jitter to rid the gridder\n",
    "\n",
    "# Nearest neighbors\n",
    "tree = cKDTree(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define all the links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for position of links\n",
    "x, y = [], []\n",
    "\n",
    "# Go through each node and construct links \n",
    "for pt in X:\n",
    "    k = int(data[int(round(pt[0])), int(round(pt[1]))] / np.max(data) * (k_max - k_min) + k_min)\n",
    "    dist, ind = tree.query(pt, k=k)\n",
    "    for kneigh in ind[1:]:\n",
    "        x.append([pt[0], X[kneigh][0]])\n",
    "        y.append([pt[1], X[kneigh][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we draw and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct figure\n",
    "plt.figure(figsize=(4*r, 4), frameon=False)\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.plot(np.array(x).T, np.array(y).T, color='#282828', lw=0.4, alpha=0.4, zorder=2) \n",
    "\n",
    "plt.axis('off')\n",
    "plt.ylim(y_norm, 0)\n",
    "plt.xlim(0, x_norm)\n",
    "\n",
    "#ax.set_ylim(ax.get_xlim()[::-1])\n",
    "plt.savefig('%s_bot%d_pow%.01fsampling_kmin%d_kmax%d.png' % (filename, nsamples, contrast, k_min, k_max), dpi=250, pad=0.0, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolving gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"ulf\"\n",
    "nsamples_min = 100     # Number of nodes in first frame\n",
    "nsamples_max = 10000   # Number of nodes in last frame\n",
    "nframes = 10           # Number of frames\n",
    "k_max = 10             # The maximum number of links per node\n",
    "k_min = 3              # The maximum number of links per node\n",
    "contrast = 2           # Increase to when skin is darker (2-3 is good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process in loop**\n",
    "\n",
    "Essentially, we just do the same as above, but now for a steadily increasing number of samples. In each iteration we draw a fixed number of new samples, and add them to the existing ones, then compute nearest neighbors and draw links for all points again. If you move `x, y = [], []` out of the loop and iterate over `X_` and not `X` in line 36, the process is marginally faster and the result will be slighly different. In the end we stitch all the frames together and create a gif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 166 278 464 774 1291 2154 3593 5994 10000\n"
     ]
    }
   ],
   "source": [
    "# Load and process data\n",
    "img = plt.imread('%s.png' % filename)\n",
    "data = rgb2gray(img)\n",
    "data = (1 - data / data.max()) * (img[:, :, 3] != 0)  # Invert and zero out background\n",
    "data = data.T                                         # Transpose coordinate rotation\n",
    "x_norm, y_norm = map(float, data.shape)\n",
    "r = x_norm / y_norm\n",
    "\n",
    "# Sample\n",
    "p_map = data**contrast / np.sum(data**contrast)        # Probability of each pixel\n",
    "\n",
    "images = []\n",
    "X = np.empty(shape=(0, 2))\n",
    "for nsamples in map(int, np.logspace(np.log10(nsamples_min), np.log10(nsamples_max), nframes)):\n",
    "    \n",
    "    ij = np.random.choice(\n",
    "        np.arange(0, data.shape[0] * data.shape[1]),       # Flattened indices\n",
    "        size=(nsamples-X.shape[0]), p=p_map.reshape(-1)\n",
    "    )\n",
    "\n",
    "    # Sampled coordinates\n",
    "    X_ = np.array(zip(\n",
    "        ij / data.shape[1],                          # x coordinates\n",
    "        ij % data.shape[1]                           # y coordinates\n",
    "    )) + (np.random.random(size=(nsamples-X.shape[0], 2))-0.5)  # small jitter to rid the gridder\n",
    "    \n",
    "    X = np.vstack([X, X_])\n",
    "    \n",
    "    outfilename = '%s_bot%d_pow%.01fsampling_kmin%d_kmax%d.png' % (filename, X.shape[0], contrast, k_min, k_max)\n",
    "    \n",
    "    if outfilename in os.listdir(\".\"):\n",
    "        print nsamples, \n",
    "         continue\n",
    "\n",
    "    # Nearest neighbors\n",
    "    tree = cKDTree(X)\n",
    "    \n",
    "    # Create lists for position of links\n",
    "    x, y = [], []\n",
    "\n",
    "    # Go through each node and construct links \n",
    "    for pt in X:\n",
    "        k = int(data[int(round(pt[0])), int(round(pt[1]))] / np.max(data) * (k_max - k_min) + k_min)\n",
    "        dist, ind = tree.query(pt, k=k)\n",
    "        for kneigh in ind[1:]:\n",
    "            x.append([pt[0], X[kneigh][0]])\n",
    "            y.append([pt[1], X[kneigh][1]])\n",
    "            \n",
    "    # Construct figure (this is the part that takes the most time)\n",
    "    plt.figure(figsize=(4*r, 4), frameon=False)\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    plt.plot(np.array(x).T, np.array(y).T, color='#282828', lw=0.4, alpha=0.4, zorder=2) \n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.ylim(y_norm, 0)\n",
    "    plt.xlim(0, x_norm)\n",
    "\n",
    "    plt.savefig(outfilename, dpi=250, pad=0.0, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    images.append(imageio.imread(\n",
    "        outfilename\n",
    "    ))\n",
    "    \n",
    "    print nsamples, \n",
    "\n",
    "# Render array of images as one gif\n",
    "imageio.mimsave(\n",
    "    '%s_bot%d_pow%.01fsampling_kmin%d_kmax%d_nsamples_%d_%d_nframes_%d.gif' % \\\n",
    "    (filename, X.shape[0], contrast, k_min, k_max, nsamples_min, nsamples_max, nframes),\n",
    "    images\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
